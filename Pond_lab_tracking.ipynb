{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Cell Tracking Script\n",
    "### Makes heavy use of the oyLabImaging package produced by Alon Oyler-Yaniv's group, which can be found at https://github.com/oylab/oyLabImaging\n",
    "#### Author: Woody March-Steinman, Program in Applied Mathematics, University of Arizona.\n",
    "- Contact: wmarchsteinman@arizona.edu\n",
    "\n",
    "This code provides a framework for a reproducible automated cell tracking pipeline using existing tools from Alon Oyler-Yaniv's lab.\n",
    "Included as additional features are the following:\n",
    "- Streamlined data output for downstream analysis\n",
    "- Calculation of frame-to-frame property deltas for some properties\n",
    "- Included analysis pipeline options, including visualization of results.\n",
    "- Fault tolerance and consistency. For large movies, this will reduce the chance of losing data after long processing times.\n",
    "\n",
    "Future versions of the code will include:\n",
    "- *Mitosis prediction, lineage tracking, and track correction* via both CDK2 marker tracking and through other prediction metrics.\n",
    "- *Death prediction*,  will require use of a standard set of metrics (typically a nuclear marker and brightfield imaging)\n",
    "- *Track correction*, aiming to use the viterbi algorithm or some variant "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec900ce",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary packages to install before use: \n",
    "pandas, pyfftw, numpy, matplotlib, oyLabImaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be3ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%gui qt\n",
    "%matplotlib qt5\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#import cupy as cpW\n",
    "\n",
    "import pandas as pd\n",
    "import pyfftw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "#from utilities.py import *\n",
    "from oyLabImaging import Metadata\n",
    "from oyLabImaging.Processing import results\n",
    "from oyLabImaging.Processing.imvisutils import get_or_create_viewer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eb37c8",
   "metadata": {},
   "source": [
    "## Data Preparation and Drift Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that you need to have the following files in the directory denoted in $\\textbf{fpath}$:\n",
    "- *movie.nd2* -- Can have any name.  Only one ND2 file per data folder.  Aim to have files with more than one frame.\n",
    "\n",
    "- *labels.csv* -- This file should contain all experimental conditions and the positions that match. (ex: Control as experiment name, 1 as starting position, 10 as ending position -- actual nd2 positions are assumed to start from 0, but use experimental positions as this is automatically handled)\n",
    "\n",
    "- *markers.csv* -- This file should contain fluorescent markers identical to the names used in the .nd2 file, and unspaced labels you wish to use to refer to them. (ex: YFP as the marker, FOXO1 as the label)\n",
    "\n",
    "**NOTE:** The code below automatically replaces spaces with underscores.  If you don't want this behavior, you can delete it, but it might cause downstream issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e30ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------- data setup -- edit names to match.  Also run from a fresh notebook before analysis. --------------------#\n",
    "movie_name = 'k_all' #no spaces, use underscores instead.\n",
    "fpath = './data/kelvin_all' #directory that nd2 file is stored in.\n",
    "mpath = './'+movie_name+'_analysis' #do not change, ideally\n",
    "\n",
    "nframes = 256\n",
    "nuc_mark = \"640S\"\n",
    "cyto_mark = \"488S\"\n",
    "\n",
    "#---------------- Don't edit below here -- Metadata loading and label generation -------------------#\n",
    "\"\"\"generate experiment labels and position ranges. \n",
    "labels.csv/markers.csv files must be in the fpath folder above, names should contain no periods or spaces.\n",
    "\"\"\"\n",
    "label_csv = pd.read_csv(fpath + \"/labels.csv\")\n",
    "labels = {}\n",
    "for i in range(len(label_csv)):\n",
    "    curr_lab = label_csv[\"experiment_label\"][i]\n",
    "    curr_lab = curr_lab.replace(\".\",\"_\")\n",
    "    curr_lab = curr_lab.replace(\" \", \"_\")\n",
    "    labels.update({curr_lab: np.array(range(label_csv[\"position_start\"][i] - 1, label_csv[\"position_end\"][i]))})\n",
    "\n",
    "marker_csv = pd.read_csv(fpath + \"/markers.csv\")\n",
    "marker_labels = {}\n",
    "for i in range(len(marker_csv)):\n",
    "    curr_lab = marker_csv[\"name\"][i]\n",
    "    curr_lab = curr_lab.replace(\".\",\"_\")\n",
    "    curr_lab = curr_lab.replace(\" \", \"_\")\n",
    "    marker_labels.update({marker_csv[\"marker\"][i]: curr_lab})\n",
    "\n",
    "#creates filepath for movie analysis.\n",
    "os.makedirs(mpath, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD = Metadata(fpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section deals with \n",
    "MD = Metadata(fpath)\n",
    "\n",
    "\n",
    "#only run this if you haven't yet for this movie.  Otherwise, delete the metadata.pickle file and re-run this.\n",
    "if np.max(MD().frame) > nframes:\n",
    "     MD().frame = MD().frame//len(set(MD()[\"Position\"]))\n",
    "     MD.save()\n",
    "\n",
    "\n",
    "# #---------------- Don't edit below here -- Drift Correction -- REQUIRES LOTS OF MEMORY-------------------#\n",
    "\n",
    "#this makes some assumptions regarding position names in the nd2 file.\n",
    "positions_to_track = []\n",
    "for i in labels.values():\n",
    "    positions_to_track = positions_to_track + list(i)\n",
    "positions_to_track = [str(i) for i in positions_to_track]\n",
    "if \"driftTform\" not in MD().columns:\n",
    "   MD.CalculateDriftCorrection(Channel=nuc_mark, GPU = False)\n",
    "\n",
    "\n",
    "#---------------- Don't edit above here -------------------#\n",
    "\n",
    "#view metadata\n",
    "MD()\n",
    "\n",
    "#uncomment to ensure metadata pickle file is saved, including drift correction\n",
    "#MD.save()\n",
    "\n",
    "\n",
    "# -- uncomment to view movie with drift correction in Napari Viewer --\n",
    "#MD.viewer() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/path\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "foo = Path(\"data\")\n",
    "bar = \"path\"\n",
    "print(foo / bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8e6338",
   "metadata": {},
   "source": [
    "# Segmentation and Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds either an empty results object or a results object generated from previously stored results data (results.pickle)\n",
    "R = results(MD=MD)\n",
    "\n",
    "R()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad34339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Segmentation and Tracking -- REQUIRES LOTS OF MEMORY/COMPUTE RESOURCES-------------------#\n",
    "\n",
    "#you can change the parameters below to the version of your choice if your segmentation runs fast, but these give fair results.  If it runs slow, keep these values.\n",
    "\n",
    "#segmentation_dict = MD.try_segmentation() -- use this if you want to use the GUI to set parameters. May need it in an earlier cell.\n",
    "segmentation_dict = {'model_name': ['2D_versatile_fluo'],\n",
    " 'scale': 1.0,\n",
    " 'prob_thresh': 0.7,\n",
    " 'nms_thresh': 0.4,\n",
    " 'vmin': 1.0,\n",
    " 'vmax': 98.0}\n",
    "\n",
    "failed = []\n",
    "reg = False\n",
    "nthreads = 16 #set this higher if you have threading enabled.  Marginal speed gains.\n",
    "\n",
    "#this is significantly slower, but doesn't destroy data already processed if a position fails.  Failed position numbers are stored in the \"failed\" list.\n",
    "if \"driftTform\" in MD().columns:\n",
    "    reg = True\n",
    "for i in positions_to_track:\n",
    "    try:\n",
    "        R.segment_and_extract_features(MD=MD,NucChannel=[nuc_mark],segment_type='stardist_nuclei' ,threads=nthreads, **segmentation_dict, register=reg, zernike=False,periring=True, Position = i)\n",
    "    except:\n",
    "        print(f\"error at position {i}.\")\n",
    "        failed.append(i)\n",
    "print(f'Positions that failed to segment: {failed}')\n",
    "\n",
    "for i in positions_to_track:\n",
    "    try:\n",
    "        R.calculate_tracks(Position=i, params=[nuc_mark], search_radius=10,adaptive_radius=True, maxStep=5,minTrackLength=nframes//2,save=True, verbose = False)\n",
    "    except:\n",
    "        print(f'Failed position: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff497c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set this value to the minimum number of frames for a track to be included in data output (default is nframes, for full tracks)\n",
    "min_track_length = nframes -1\n",
    "\n",
    "'''generates tracks of at least thresh length. Returns the useful tracks and their indices.\n",
    "'''\n",
    "def gen_full_tracks(track_ind_array, thresh = 1):\n",
    "    useful_tracks = []\n",
    "    ind_arr = []\n",
    "    for ind, track in enumerate(track_ind_array):\n",
    "        s = np.sum(track == None)\n",
    "        if s <= thresh:\n",
    "            useful_tracks.append(track)\n",
    "            ind_arr.append(ind)\n",
    "    return useful_tracks,ind_arr\n",
    "\n",
    "#handling data and processing\n",
    "\n",
    "#generate all relevant data -- this can potentially be edited, but be careful.\n",
    "all_tracks = []\n",
    "for pos in R.PosLbls.keys():\n",
    "    g = R.PosLbls[pos]\n",
    "    track_inds, track_labels = gen_full_tracks(g.trackinds, thresh = (nframes - min_track_length + 1))\n",
    "    for ind, track in enumerate(track_inds):\n",
    "        info_dict = {}\n",
    "        for frame_ind, obj_id in enumerate(track):\n",
    "            frame_dict = {}\n",
    "            curr_frame = g.framelabels[frame_ind]\n",
    "            next_frame = None\n",
    "            if (frame_ind + 1 < len(track) and track[frame_ind + 1] != None):\n",
    "                next_frame = g.framelabels[frame_ind+1]\n",
    "            if obj_id == None:\n",
    "                pass\n",
    "            else:\n",
    "                next_frame = g.framelabels[frame_ind+1]\n",
    "                frame_dict[\"position\"] = pos\n",
    "                frame_dict[\"track_id\"] = track_labels[ind]#ind -- updated for useful tracks\n",
    "                frame_dict[\"frame_id\"] = frame_ind\n",
    "                frame_dict[\"object_id\"] = obj_id\n",
    "                frame_dict[\"weighted_centroid_x\"] = curr_frame.regionprops['weighted_centroid'][obj_id][0]\n",
    "                frame_dict[\"weighted_centroid_y\"] = curr_frame.regionprops['weighted_centroid'][obj_id][1]\n",
    "                if next_frame != None and track[frame_ind + 1] != None:\n",
    "                    frame_dict[\"vel\"] = math.dist(curr_frame.regionprops['centroid'][obj_id], next_frame.regionprops['centroid'][track[frame_ind+1]])\n",
    "                    frame_dict[\"radius_delta\"] = next_frame.regionprops['equivalent_diameter'][track[frame_ind + 1]]/2 - curr_frame.regionprops['equivalent_diameter'][obj_id]/2\n",
    "                    frame_dict[\"area_delta\"] = next_frame.regionprops['area'][track[frame_ind + 1]] - curr_frame.regionprops['area'][obj_id]\n",
    "                    frame_dict[\"solidity_delta\"] = next_frame.regionprops['solidity'][track[frame_ind + 1]] - curr_frame.regionprops['solidity'][obj_id]\n",
    "                    #include this if you use phase.\n",
    "                    #frame_dict[\"phase_delta\"] = next_frame.regionprops['mean_Phase'][track[frame_ind + 1]] - curr_frame.regionprops['mean_Phase'][obj_id]\n",
    "                    frame_dict[\"nuc_delta\"] = next_frame.regionprops['mean_'+nuc_mark][track[frame_ind + 1]] - curr_frame.regionprops['mean_'+nuc_mark][obj_id]\n",
    "                else:\n",
    "                    frame_dict[\"vel\"] = 0\n",
    "                    frame_dict[\"radius_delta\"] = 0\n",
    "                    frame_dict[\"area_delta\"] = 0\n",
    "                    frame_dict[\"solidity_delta\"] = 0\n",
    "                frame_dict[\"area\"] = curr_frame.regionprops['area'][obj_id]\n",
    "                frame_dict[\"solidity\"] = curr_frame.regionprops['solidity'][obj_id]\n",
    "                frame_dict[\"radius\"] = curr_frame.regionprops['equivalent_diameter'][obj_id]/2\n",
    "                frame_dict[\"nuclear_marker\"] = curr_frame.regionprops['mean_'+nuc_mark][obj_id]\n",
    "                #include this if you use phase\n",
    "                #frame_dict[\"phase\"] = curr_frame.regionprops['mean_Phase'][obj_id] \n",
    "                for k in marker_labels.keys():\n",
    "                    nuc = curr_frame.regionprops['mean_'+k][obj_id]\n",
    "                    cyt = curr_frame.regionprops['mean_'+k+'_periring'][obj_id]\n",
    "                    radius = curr_frame.regionprops['equivalent_diameter'][obj_id]/2\n",
    "                    frame_dict[marker_labels[k]+\"_nuc\"] = nuc\n",
    "                    frame_dict[marker_labels[k]+\"_cyt\"] = cyt\n",
    "                    #generate ratios for all markers\n",
    "                    area = curr_frame.regionprops['area'][obj_id]\n",
    "                    peri_area = (radius + 5)**2 * np.pi - area\n",
    "                    frame_dict[marker_labels[k]+\"_ratio\"] = nuc/(cyt + nuc)\n",
    "                all_tracks.append(frame_dict)\n",
    "\n",
    "#reformat and save to directory\n",
    "all_tracks_dataframe = pd.DataFrame(all_tracks)\n",
    "os.makedirs(\"./\"+movie_name + \"_analysis/csv_predict\", exist_ok=True)\n",
    "all_tracks_dataframe.to_csv(mpath + \"/csv_predict/all_tracks_dataframe.csv\")\n",
    "#---------------- don't edit above here -------------#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(mpath + \"/graphs\", exist_ok=True)\n",
    "os.makedirs(mpath + \"/formatted_data\", exist_ok=True)\n",
    "data = pd.read_csv(mpath + \"/csv_predict/all_tracks_dataframe.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all cells area\n",
    "plt.hist(data.area[data.area], bins = 100)\n",
    "plt.show()\n",
    "\n",
    "# The below code gets rid of cells under a certain size.  \n",
    "# You can implement further cell track quality control here using the same ideas with different fields.\n",
    "# bad_tracks = data[data.area < 200][['position', 'track_id']]\n",
    "# g = bad_tracks.groupby(bad_tracks.columns.tolist(),as_index=False).size()\n",
    "# g = g[g['size'] > 30]\n",
    "# g = g.reset_index()\n",
    "\n",
    "# #remove all data that doesn't fit qc standards (area, etc)\n",
    "# for ind, pos in enumerate(g['position']):\n",
    "#     data = data[~(np.array(data.position == pos) & np.array(data.track_id == g['track_id'][ind]))]\n",
    "#     data = data[~(np.array(data.position == pos) & np.array(data.track_id == g['track_id'][ind]))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e55cf78",
   "metadata": {},
   "source": [
    "The below blocks are older code that can be modified to show graphs across experimental conditions based on position.  They'll need some modification, but the idea is there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Position graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lower = np.array(list(labels.values()))[:,0]\n",
    "upper = np.array(list(labels.values()))[:,0]\n",
    "data_to_analyze = data.copy()\n",
    "all_foxo = []\n",
    "all_foxo_std = []\n",
    "all_p53 = []\n",
    "all_p53_std = []\n",
    "for i in range(len(lower)):\n",
    "    l = data_to_analyze.position >= lower[i]\n",
    "    u = data_to_analyze.position <= upper[i]\n",
    "    both = l & u\n",
    "    pos_subset = data_to_analyze[both]\n",
    "    foxo_ratio = []\n",
    "    foxo_std = []\n",
    "    p53_nuc = []\n",
    "    p53_std = []\n",
    "    for i in range(len(set(pos_subset.frame_id))):\n",
    "        data_subset = pos_subset[pos_subset.frame_id == i]\n",
    "        foxo_ratio.append(np.mean(data_subset.red_ratio))\n",
    "        foxo_std.append(np.std(data_subset.red_ratio)/np.sqrt(len(data_subset.red_ratio)))\n",
    "        p53_nuc.append(np.mean(data_subset.blue_nuc))\n",
    "        p53_std.append(np.std(data_subset.blue_nuc)/np.sqrt(len(data_subset.blue_nuc)))\n",
    "    all_foxo.append(np.array(foxo_ratio))\n",
    "    all_p53.append(np.array(p53_nuc))\n",
    "    all_foxo_std.append(np.array(foxo_std))\n",
    "    all_p53_std.append(np.array(p53_std))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze = data.copy()\n",
    "all_foxo = []\n",
    "all_foxo_std = []\n",
    "all_p53 = []\n",
    "all_p53_std = []\n",
    "for i in range(len(lower)):\n",
    "    l = data_to_analyze.position >= lower[i]*10\n",
    "    u = data_to_analyze.position < upper[i]*10\n",
    "    both = l & u\n",
    "    pos_subset = data_to_analyze[both]\n",
    "    foxo_ratio = []\n",
    "    foxo_std = []\n",
    "    p53_nuc = []\n",
    "    p53_std = []\n",
    "    for i in range(len(set(pos_subset.frame_id))):\n",
    "        data_subset = pos_subset[pos_subset.frame_id == i]\n",
    "        foxo_ratio.append(np.mean(data_subset.yfp_ratio))\n",
    "        foxo_std.append(np.std(data_subset.yfp_ratio)/np.sqrt(len(data_subset.yfp_ratio)))\n",
    "        p53_nuc.append(np.mean(data_subset.p53_nuc))\n",
    "        p53_std.append(np.std(data_subset.p53_nuc)/np.sqrt(len(data_subset.p53_nuc)))\n",
    "    all_foxo.append(np.array(foxo_ratio))\n",
    "    all_p53.append(np.array(p53_nuc))\n",
    "    all_foxo_std.append(np.array(foxo_std))\n",
    "    all_p53_std.append(np.array(p53_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(labels.keys()))\n",
    "nframes = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(fpath + '/graphs/experiments', exist_ok=True)\n",
    "plt.figure(figsize=(8,6))\n",
    "for i in range(len(all_foxo)):\n",
    "    fig, graph = plt.subplots()\n",
    "    t = np.linspace(.25,(nframes)//12, nframes)\n",
    "    l1 = graph.plot(t, all_foxo[i], color = 'red', label = \"Mean blue ratio sig\")\n",
    "    ci_lower_f = all_foxo[i] - all_foxo_std[i] * 2\n",
    "    ci_upper_f = all_foxo[i] + all_foxo_std[i] * 2\n",
    "    l2 = graph.fill_between(t, ci_lower_f, ci_upper_f, color='red', alpha=.15, label = \"blue%CI\")\n",
    "    graph.set_ylabel('blue ratio', color = 'blue')\n",
    "    graph.tick_params(axis = 'y', labelcolor = 'blue')\n",
    "    graph.set_ylim(0.5, 2.5)\n",
    "    graph.xaxis.set_ticks(np.arange(0, 8, 1))\n",
    "    plt.legend([\"blue ratio\", \"blue%CI\"], loc = 2)\n",
    "\n",
    "    g2 = graph.twinx()\n",
    "    l3 = g2.plot(t, all_p53[i], label = \"nuc sig\")\n",
    "    ci_lower_p = all_p53[i] - all_p53_std[i] * 2\n",
    "    ci_upper_p = all_p53[i] + all_p53_std[i] * 2\n",
    "    l4 = g2.fill_between(t, ci_lower_p, ci_upper_p, color='b', alpha=.15, label = \"nuc%CI\")\n",
    "    g2.set_ylabel('nuc', color = 'b')\n",
    "    g2.tick_params(axis = 'y', labelcolor = 'b')\n",
    "    g2.set_ylim(0, 1)\n",
    "    fig.tight_layout() \n",
    "\n",
    "\n",
    "    plt.title(f'Positions {lower[i] + 1} to {upper[i]} -- {list(labels.keys())[i]}')\n",
    "    plt.xlim(0, 8)\n",
    "    #plt.legend([\"Mean h3 ratio\", \"h3_95%CI\"], loc = 4)\n",
    "\n",
    "    #plt.savefig(path + '/graphs/experiments/pos'+str(lower[i] +1)+'_'+str(upper[i])+'_combined.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p53 or foxo graphs\n",
    "lab = list(labels.keys())\n",
    "os.makedirs(mpath + \"/graphs/experiments/p53\", exist_ok = True)\n",
    "os.makedirs(mpath + \"/graphs/experiments/foxo\", exist_ok = True)\n",
    "foxo_g = False\n",
    "flab = \"\"\n",
    "nframes = 145\n",
    "if (foxo_g):\n",
    "    flab = \"foxo\"\n",
    "else:\n",
    "    flab = \"p53\"\n",
    "for i in range(len(all_foxo)):\n",
    "    fig, graph = plt.subplots()\n",
    "    t = np.linspace(0,nframes//3, nframes-1)\n",
    "    if foxo_g:\n",
    "        graph.plot(t, all_foxo[i], color = 'red')\n",
    "        ci_lower_f = all_foxo[i] - all_foxo_std[i] * 2\n",
    "        ci_upper_f = all_foxo[i] + all_foxo_std[i] * 2\n",
    "        graph.fill_between(t, ci_lower_f, ci_upper_f, color='red', alpha=.15)\n",
    "        plt.legend([\"Mean Foxo Nuc-Cyto Ratio\", \"f_ratio_95%CI\"])\n",
    "\n",
    "    else:\n",
    "        graph.plot(t, all_p53[i])\n",
    "        ci_lower_p = all_p53[i] - all_p53_std[i] * 2\n",
    "        ci_upper_p = all_p53[i] + all_p53_std[i] * 2\n",
    "        graph.fill_between(t, ci_lower_p, ci_upper_p, color='b', alpha=.15)\n",
    "        plt.legend([\"Mean p53 Nuclear Signal\", \"p53_95%CI\"])\n",
    "\n",
    "    plt.title(f'Positions {lower[i] + 1} to {upper[i]} -- {lab[i]}')\n",
    "    plt.xlim(0, 48)\n",
    "    #plt.ylim(0, .65)\n",
    "    plt.savefig(path + '/graphs/experiments/'+flab+'/pos'+str(lower[i] +1)+'_'+str(upper[i]+1)+'_'+flab+'.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Position Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for single positions\n",
    "positions_to_track = []\n",
    "for i in labels.values():\n",
    "    positions_to_track = positions_to_track + list(i)\n",
    "positions_to_track = [str(i) for i in positions_to_track]\n",
    "data_to_analyze = data.copy()\n",
    "all_foxo = []\n",
    "all_foxo_std = []\n",
    "all_p53 = []\n",
    "all_p53_std = []\n",
    "for pos in positions_to_track:\n",
    "    both = data_to_analyze.position == int(pos)\n",
    "    pos_subset = data_to_analyze[both]\n",
    "    foxo_ratio = []\n",
    "    foxo_std = []\n",
    "    p53_nuc = []\n",
    "    p53_std = []\n",
    "    for i in range(len(set(pos_subset.frame_id))):\n",
    "        data_subset = pos_subset[pos_subset.frame_id == i]\n",
    "        foxo_ratio.append(np.mean(data_subset.red_ratio))\n",
    "        foxo_std.append(np.std(data_subset.red_ratio)/np.sqrt(len(data_subset.red_ratio)))\n",
    "        p53_nuc.append(np.mean(data_subset.blue_nuc))\n",
    "        p53_std.append(np.std(data_subset.blue_nuc)/np.sqrt(len(data_subset.blue_nuc)))\n",
    "    all_foxo.append(np.array(foxo_ratio))\n",
    "    all_p53.append(np.array(p53_nuc))\n",
    "    all_foxo_std.append(np.array(foxo_std))\n",
    "    all_p53_std.append(np.array(p53_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single positions\n",
    "labels = [\"0\"]\n",
    "os.makedirs(fpath + \"/graphs/single_positions/combined\", exist_ok = True)\n",
    "#labels = [\"exp1\", \"exp2\", \"exp3\"]\n",
    "for i in range(len(all_foxo)):\n",
    "    fig, graph = plt.subplots()\n",
    "    t = np.linspace(0,len(all_foxo[i])//4, len(all_foxo[i]))\n",
    "    graph.plot(t, all_foxo[i], color = 'red')\n",
    "    ci_lower_f = all_foxo[i] - all_foxo_std[i] * 2\n",
    "    ci_upper_f = all_foxo[i] + all_foxo_std[i] * 2\n",
    "    graph.fill_between(t, ci_lower_f, ci_upper_f, color='red', alpha=.15)\n",
    "    graph.plot(t, all_p53[i])\n",
    "    ci_lower_p = all_p53[i] - all_p53_std[i] * 2\n",
    "    ci_upper_p = all_p53[i] + all_p53_std[i] * 2\n",
    "    graph.fill_between(t, ci_lower_p, ci_upper_p, color='b', alpha=.15)\n",
    "    plt.title(f'Position {lower[i]} -- {labels[i//10]}')\n",
    "    plt.xlim(0, 24)\n",
    "    plt.legend([\"Mean Foxo Nuc-Cyto Ratio\", \"f_ratio_95%CI\", \"Mean p53 Nuclear Signal\", \"p53_95%CI\"])\n",
    "    #plt.ylim(0, 1)\n",
    "    plt.savefig(fpath + '/graphs/single_positions/combined/pos'+str(lower[i])+'_combined.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single positions foxo or p53\n",
    "#labels = [\"2\", \"1\", \"0.75\", \"0.5\", \"0.05\", \"0.1\", \"0.25\", \"0.01\", \"UT\"]\n",
    "os.makedirs(path + \"/graphs/single_positions/p53\", exist_ok = True)\n",
    "os.makedirs(path + \"/graphs/single_positions/foxo\", exist_ok = True)\n",
    "foxo_g = True\n",
    "flab = \"\"\n",
    "if (foxo_g):\n",
    "    flab = \"foxo\"\n",
    "else:\n",
    "    flab = \"p53\"\n",
    "#labels = [\"exp1\", \"exp2\", \"exp3\"]\n",
    "for i in range(len(all_foxo)):\n",
    "    fig, graph = plt.subplots()\n",
    "    t = np.linspace(0,len(all_foxo[i])//3, len(all_foxo[i]))\n",
    "    if (foxo_g):\n",
    "        graph.plot(t, all_foxo[i], color = 'red')\n",
    "        ci_lower_f = all_foxo[i] - all_foxo_std[i] * 2\n",
    "        ci_upper_f = all_foxo[i] + all_foxo_std[i] * 2\n",
    "        graph.fill_between(t, ci_lower_f, ci_upper_f, color='red', alpha=.15)\n",
    "        plt.legend([\"Mean Foxo Nuc-Cyto Ratio\", \"f_ratio_95%CI\"])\n",
    "\n",
    "    else:\n",
    "        graph.plot(t, all_p53[i])\n",
    "        ci_lower_p = all_p53[i] - all_p53_std[i] * 2\n",
    "        ci_upper_p = all_p53[i] + all_p53_std[i] * 2\n",
    "        graph.fill_between(t, ci_lower_p, ci_upper_p, color='b', alpha=.15)\n",
    "        plt.legend([\"Mean p53 Nuclear Signal\", \"p53_95%CI\"])\n",
    "\n",
    "    plt.title(f'Position {positions_to_track[i]} -- {list(labels.keys())[i//10]}')\n",
    "    plt.xlim(0, 96)\n",
    "    plt.ylim(.4, .75)\n",
    "    plt.savefig(path + '/graphs/single_positions/'+flab+'/pos'+positions_to_track[i]+'_'+flab+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Track Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = np.array(list(labels.values()))[:,0] #choose tracks from each of 10 positions\n",
    "#position = np.array([0, 1, 2])\n",
    "data_to_analyze = data.copy()\n",
    "all_foxo = []\n",
    "all_p53 = []\n",
    "n_tracks_per_pos = 10\n",
    "for i, val in enumerate(position):\n",
    "    pos = data_to_analyze.position == val\n",
    "    pos_subset = data_to_analyze[pos]\n",
    "    track_list = np.array(list(set(pos_subset.track_id)))\n",
    "    tracks_to_plot = np.random.choice(track_list, min(len(track_list), n_tracks_per_pos), replace = False)\n",
    "    for j, track in enumerate(tracks_to_plot):\n",
    "        data_subset = pos_subset[pos_subset.track_id == track]\n",
    "        all_foxo.append([(val, track),np.array(data_subset.blue_ratio)])\n",
    "        all_p53.append([(val, track),np.array(data_subset.red_nuc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphing single-cell trajectories\n",
    "#labels = [\"exp1\", \"exp2\", \"exp3\"]\n",
    "lab = list(labels.keys())\n",
    "os.makedirs(mpath + \"/graphs/single_tracks/combined\", exist_ok=True)\n",
    "\n",
    "for i in range(len(all_foxo)):\n",
    "    fig, graph = plt.subplots()\n",
    "    curr_data_f = all_foxo[i]\n",
    "    curr_data_p = all_p53[i]\n",
    "    pos = curr_data_f[0][0]\n",
    "    track = curr_data_f[0][1]\n",
    "    t = np.linspace(0,len(curr_data_f[1])//4, len(curr_data_f[1]))\n",
    "    graph.plot(t, curr_data_f[1], color = 'red')\n",
    "    graph.plot(t, curr_data_p[1])\n",
    "    plt.title(f'Position {pos}, Track {track}-- {lab[pos//10]}')\n",
    "    plt.xlim(0, 64)\n",
    "    plt.legend([\"Foxo Nuc-Cyto Ratio\", \"p53 Nuclear Signal\"])\n",
    "    #plt.ylim(0, 1)\n",
    "    plt.savefig(mpath + '/graphs/single_tracks/combined/pos'+str(pos)+'_track'+str(track)+'_combined.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphing single tracks foxo or p53\n",
    "\n",
    "lab = list(labels.keys())\n",
    "os.makedirs(mpath + \"/graphs/single_tracks/p53\", exist_ok = True)\n",
    "os.makedirs(mpath + \"/graphs/single_tracks/foxo\", exist_ok = True)\n",
    "foxo_g = True\n",
    "flab = \"\"\n",
    "if (foxo_g):\n",
    "    flab = \"foxo\"\n",
    "else:\n",
    "    flab = \"p53\"\n",
    "for i in range(len(all_foxo)):\n",
    "    fig, graph = plt.subplots()\n",
    "    curr_data_f = all_foxo[i]\n",
    "    #curr_data_p = all_p53[i]\n",
    "    pos = curr_data_f[0][0]\n",
    "    track = curr_data_f[0][1]\n",
    "    t = np.linspace(0,len(curr_data_f[1])//3, len(curr_data_f[1]))\n",
    "    if foxo_g:\n",
    "        graph.plot(t, curr_data_f[1], color = 'red')\n",
    "        plt.legend([\"Foxo Nuclear Fraction\"])\n",
    "    else:\n",
    "        graph.plot(t, curr_data_p[1])\n",
    "        plt.legend([\"p53 Nuclear Signal\"])\n",
    "\n",
    "    plt.title(f'Position {pos}, Track {track}-- {list(labels.keys())[i//10]}')\n",
    "    plt.xlim(0, 24)\n",
    "    plt.ylim(0.35, .8)\n",
    "    plt.savefig(mpath + '/graphs/single_tracks/'+flab+'/pos'+str(pos)+'_track'+str(track)+'_'+flab+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating heatmaps from all single-cell traces. -- This is older and not necessarily useful anymore.\n",
    "#use nan data.\n",
    "\n",
    "def generate_heatmap_array(data, timepoints, field, positions = None):\n",
    "    num_pos = list(set(data.position))\n",
    "    if positions != None:\n",
    "        num_pos = positions\n",
    "    num_rows = 0\n",
    "    for i in range(len(num_pos)):\n",
    "        num_tracks = list(set(data[data.position == num_pos[i]].track_id))\n",
    "        num_rows += len(num_tracks)\n",
    "    heatmap_array = np.empty((num_rows, timepoints))\n",
    "    row_count = 0\n",
    "    for i in range(len(num_pos)):\n",
    "        pos_data = data[data.position == num_pos[i]]\n",
    "        for id, track in enumerate(list(set(pos_data.track_id))):\n",
    "            track_data = pos_data[pos_data.track_id == track]\n",
    "            for row in range(len(track_data)):\n",
    "                fr = track_data.iloc[row,:]\n",
    "                frame_id = fr.frame_id\n",
    "                heatmap_array[row_count, int(frame_id)] = fr[field]\n",
    "            row_count +=1\n",
    "    return heatmap_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothing function, identify width, default is to normalize data prior to smoothing, window width set to 5.\n",
    "def smooth(data, width = 5, norm = True):\n",
    "    data_norm = data.copy()\n",
    "    if norm:\n",
    "        data_norm = (data - np.mean(data))/np.std(data)\n",
    "    cumsum_vec = np.cumsum(np.insert(data_norm, 0, 0)) \n",
    "    ma_vec = (cumsum_vec[width:] - cumsum_vec[:-width]) / width\n",
    "    return ma_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "div_counts = []\n",
    "channel = \"red_nuc\"\n",
    "channel2 = \"blue_ratio\"\n",
    "position = np.array(list(labels.values()))[:,0] \n",
    "#position = np.array([0, 1, 2])\n",
    "data_to_analyze = data.copy()\n",
    "for i, val in enumerate(position):\n",
    "    pos = data_to_analyze.position == val\n",
    "    pos_subset = data_to_analyze[pos]\n",
    "    track_list = np.array(list(set(pos_subset.track_id)))\n",
    "    for j, track in enumerate(track_list):\n",
    "        data_subset = pos_subset[pos_subset.track_id == track]\n",
    "        thresh = .08\n",
    "        dat = smooth(data_subset[channel],4) + smooth(data_subset[channel2], 4)\n",
    "        dat_e = np.exp(dat)/sum(np.exp(dat))\n",
    "        div_counts.append([(val, track),\n",
    "                           find_peaks(dat_e, distance = 45,prominence = thresh)])\n",
    "        #all_p53.append([(val, track),np.array(data_subset.p53_nuc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 68\n",
    "#plt.plot(t,smooth(data_to_analyze[data_to_analyze.track_id == tr].red_nuc))\n",
    "#plt.plot(t,smooth(data_to_analyze[data_to_analyze.track_id == tr].blue_ratio))\n",
    "for i in list(set(data_to_analyze.track_id)):\n",
    "    t = range(len(data_to_analyze[data_to_analyze.track_id == i].blue_ratio)-4)\n",
    "    dat = smooth(data_to_analyze[data_to_analyze.track_id == i].blue_ratio) + smooth(data_to_analyze[data_to_analyze.track_id == i].red_nuc)\n",
    "    dat_e = np.exp(dat)/sum(np.exp(dat))\n",
    "    plt.plot(t,dat_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 68\n",
    "#plt.plot(t,smooth(data_to_analyze[data_to_analyze.track_id == tr].red_nuc))\n",
    "#plt.plot(t,smooth(data_to_analyze[data_to_analyze.track_id == tr].blue_ratio))\n",
    "t = range(len(data_to_analyze[data_to_analyze.track_id == tr].blue_ratio)-4)\n",
    "dat = smooth(data_to_analyze[data_to_analyze.track_id == tr].blue_ratio) + smooth(data_to_analyze[data_to_analyze.track_id == tr].red_nuc)\n",
    "dat_e = np.exp(dat)/sum(np.exp(dat))\n",
    "plt.plot(t[10:50],dat[10:50])\n",
    "plt.plot(t,dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 27\n",
    "#plt.plot(t,smooth(data_to_analyze[data_to_analyze.track_id == tr].red_nuc, norm = False))\n",
    "plt.plot(t,smooth(data_to_analyze[data_to_analyze.track_id == tr].blue_ratio, norm = False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.exp(1- data_to_analyze.blue_ratio)/np.sum(np.exp(1- data_to_analyze.blue_ratio)), bins = 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates opposite ratio for C/N data, binarizes based on threshold (Active True vs. inactive False)\n",
    "data[\"c_n_ratio\"] = 1 - data.blue_ratio\n",
    "data[\"c_n_binary\"] = [int(i) for i in (data[\"c_n_ratio\"] > 0.50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(data_to_analyze[data_to_analyze.track_id == 27].c_n_ratio)\n",
    "val = 20\n",
    "plt.plot(np.round(smooth(data[data.track_id == val].c_n_binary, norm = False, width = 8)))\n",
    "plt.plot(smooth(data[data.track_id == val].c_n_ratio, norm = False))\n",
    "plt.plot(smooth(data[data.track_id == val].red_nuc, norm = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for inspection of data.\n",
    "val = 2\n",
    "k = data[data.track_id == val].red_nuc\n",
    "g = smooth(k, norm = False) \n",
    "gdiff = g[1:] - g[:-1]\n",
    "gdiff2 = gdiff[1:] - gdiff[:-1]\n",
    "norm_gdiff = (gdiff - np.mean(gdiff))/np.std(gdiff)\n",
    "\n",
    "#plt.plot(norm_gdiff >=4)\n",
    "#plt.plot(g[1:] - g[:-1])\n",
    "#plt.plot(lev)\n",
    "print(np.argmax(k[1:]))\n",
    "print(np.argmax(g))\n",
    "plt.plot(range(len(k)-1), k[1:])\n",
    "plt.plot(range(len(g)), g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef917845",
   "metadata": {},
   "source": [
    "### This section and the next are important for heatmap ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------condensed version of code----------------------------#\n",
    "\n",
    "#import the regular expression package\n",
    "import re\n",
    "\n",
    "#unique track ids in data -- you'd need to subset data if you have multiple positions, but this works if you have one position\n",
    "track_list = list(set(data.track_id))\n",
    "track_peaks = [] #used for downstream analysis -- will have a list of all timepoints above a 4.2 SD threshold in the nuclear channel velocity.\n",
    "#track_peaks stores arrays of the format [track_id, peak_list] for each track.\n",
    "\n",
    "#move through all tracks\n",
    "for ind, track in enumerate(track_list):\n",
    "    #smooth nuclear data and store the delta nuc values (velocity values) in gdiff, then standardize\n",
    "    g = smooth(data[data.track_id == track].red_nuc, norm = False) \n",
    "    gdiff = g[1:] - g[:-1] #note, this subtracts 1 from the real index when applied.\n",
    "    norm_gdiff = (gdiff - np.mean(gdiff))/np.std(gdiff)\n",
    "\n",
    "    #Now analyze\n",
    "    where_split = np.where(norm_gdiff >=4.2) #where are velocity peaks greater than 4.2 standard deviations above the mean? using this\n",
    "    smoothed_binary = [int(round(i)) for i in smooth(data[data.track_id == track].c_n_binary, norm = False)] #smoothed binary to find transitions.\n",
    "    stringified_bin = ''.join(map(str, smoothed_binary)) #convert to string\n",
    "    already_on = stringified_bin.find('1') #using this to find on values.\n",
    "    if already_on == -1: # if there are no CDK2 on events\n",
    "        track_peaks.append([track, []]) #add no peaks for that track\n",
    "    else:\n",
    "        track_peaks.append([track, where_split[0] + 1]) #add peaks 1 later due to velocity conversion. -- where_split[0] takes the position list from np.where.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section does the heavy lifting related to determining division events and timing.  Not all fields are used. -- old version\n",
    "import re\n",
    "\n",
    "track_list = list(set(data.track_id))\n",
    "track_vals = np.zeros((len(track_list), 5))\n",
    "track_peaks = []\n",
    "track_peaks2 = []\n",
    "for ind, track in enumerate(track_list):\n",
    "    g = smooth(data[data.track_id == track].red_nuc, norm = False) \n",
    "    gdiff = g[1:] - g[:-1]\n",
    "    norm_gdiff = (gdiff - np.mean(gdiff))/np.std(gdiff)\n",
    "    where_split = np.where(norm_gdiff >=4.2) #where are velocity peaks greater than 4.2 standard deviations above the mean? using this\n",
    "    smoothed_binary = [int(round(i)) for i in smooth(data[data.track_id == track].c_n_binary, norm = False)] #smoothed binary to find transitions.\n",
    "    stringified_bin = ''.join(map(str, smoothed_binary))\n",
    "    first_off = stringified_bin.find('10')\n",
    "    first_on = stringified_bin.find('01')\n",
    "    already_on = stringified_bin.find('1') #using this\n",
    "    count_div = len([m.start() for m in re.finditer('10', stringified_bin)]) #use string finder to count transitions from on to off.\n",
    "    if already_on == -1:\n",
    "        track_peaks.append([track, []]) #if no CDK transition, add no peaks\n",
    "    else:\n",
    "        track_peaks.append([track, where_split[0] + 1]) #add peak 1 later due to velocity conversion.\n",
    "        track_peaks2.append([track, np.where(g -np.min(g) >=0.05)]) #Alternate method for calculating peaks.\n",
    "    track_vals[ind,0] = first_off\n",
    "    track_vals[ind,1] = first_on\n",
    "    track_vals[ind,2] = already_on\n",
    "    track_vals[ind,3] = count_div\n",
    "    track_vals[ind,4] = track\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#goal -- find max value in interval of three to each side around these elements.\n",
    "#Order of events:\n",
    "#If peaks exist, find the biggest value in data for each found peak, append to location list.\n",
    "#This gets rid of duplicate events where multiple points in a sequence are above the 4.2 threshold.\n",
    "#Count elements to determine number of divisions.\n",
    "count_arr = np.zeros((len(track_peaks), 3)) #for storage, format is [track_id, num_divisions, time_of_first_division]\n",
    "div_arr = []\n",
    "for ind, row in enumerate(track_peaks):\n",
    "    track = row[0] #track id\n",
    "    vals = row[1] #potential peak positions\n",
    "    count_arr[ind, 0] = track\n",
    "    g = smooth(data[data.track_id == track].red_nuc, norm = False)  #smoothed nuclear marker data, non-normalized\n",
    "    g = g - np.min(g) #leveled data (starts from zero)\n",
    "    if len(vals) != 0:\n",
    "        temp_arr = []\n",
    "        for val in vals:\n",
    "            temp_arr.append(np.max(g[val - 3:val + 6])) #store the maximum value in a window centered around the current potential peak\n",
    "        time_first = np.where(g == temp_arr[0])[0] #find the location in nuc of the first peak\n",
    "        div_arr.append([track, [np.where(g == r)[0][0] + 1 for r in list(set(temp_arr))]]) #stores the location of all true divisions -- not used here\n",
    "        count_arr[ind, 1] = len(list(set(temp_arr))) #counts number of peaks\n",
    "        count_arr[ind, 2] = time_first[0] + 1 #stores first location of first peak.\n",
    "    else:\n",
    "        div_arr.append([track, []]) #if no peaks, add empty list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#develop ordering by time of first division.\n",
    "df = pd.DataFrame(count_arr, dtype='int')\n",
    "df.columns = [\"track\", \"divs\", \"first_div\"]\n",
    "heatmap_ordering = df.sort_values(by = ['divs', 'first_div'], ascending = [False, True]) #generate ordering based on divs, then time to first division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nframes = 256\n",
    "interval = 0.25 #interval between frames, in hours\n",
    "hm_marker = \"c_n_ratio\"\n",
    "#marker heatmap data\n",
    "heatmap_data = np.zeros((len(heatmap_ordering), nframes)) #make a rectangular array of number of tracks by number of frames\n",
    "for ind, track in enumerate(heatmap_ordering.track): #for each track in order\n",
    "    sub_data = data[data.track_id == track] #find the data from that track\n",
    "    min_frame = np.min(sub_data.frame_id) #find the minimum frame id from that track\n",
    "\n",
    "    #store the data from the desired hm_marker in the proper place in the heatmap array, starting from min_frame\n",
    "    heatmap_data[ind, min_frame:min_frame + len(sub_data[hm_marker])] = sub_data[hm_marker] \n",
    "\n",
    "hm_marker = \"red_nuc\"\n",
    "heatmap_data2 = np.zeros((len(heatmap_ordering), nframes))\n",
    "for ind, track in enumerate(heatmap_ordering.track):\n",
    "    sub_data = data[data.track_id == track]\n",
    "    min_frame = np.min(sub_data.frame_id)\n",
    "    heatmap_data2[ind, min_frame:min_frame + len(sub_data[hm_marker])] = sub_data[hm_marker]\n",
    "\n",
    "#division heatmap data\n",
    "heatmap_divs = np.zeros((len(heatmap_ordering), nframes))\n",
    "for ind, index in enumerate(heatmap_ordering.index):\n",
    "    for val in div_arr[index][1]:\n",
    "        heatmap_divs[ind,val:] +=1\n",
    "times = np.linspace(0, len(heatmap_data[0])-1, nframes)*interval\n",
    "df_hm_data = pd.DataFrame(heatmap_data, columns = times)\n",
    "df_hm_data2 = pd.DataFrame(heatmap_data2, columns = times)\n",
    "df_hm_div = pd.DataFrame(heatmap_divs, columns = times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(mpath + \"/graphs/experiments/heatmaps\", exist_ok=True)\n",
    "plt.rcParams[\"figure.figsize\"] = 6,6\n",
    "\n",
    "r = sns.heatmap(df_hm_data, cmap = \"viridis\", vmin = 0.4, annot = False) #use the dataframe with ordered heatmap data, choose minima and maxima wisely\n",
    "r.set_facecolor('gray')\n",
    "plt.title(\"CDK2 activity\")\n",
    "plt.xlabel(\"Time (hrs)\")\n",
    "plt.ylabel(\"Cell trace\")\n",
    "plt.savefig(mpath + \"/graphs/experiments/heatmaps/CDK_activity.svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(mpath + \"/graphs/experiments/heatmaps\", exist_ok=True)\n",
    "plt.rcParams[\"figure.figsize\"] = 6,6\n",
    "\n",
    "r = sns.heatmap(df_hm_data2, cmap = \"viridis\", vmin = 0.06, annot = False)\n",
    "r.set_facecolor('gray')\n",
    "plt.title(\"Nuclear marker intensity\")\n",
    "plt.xlabel(\"Time (hrs)\")\n",
    "plt.ylabel(\"Cell trace\")\n",
    "plt.savefig(mpath + \"/graphs/experiments/heatmaps/red_nuc.svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.heatmap(df_hm_div, cmap = \"viridis\")\n",
    "plt.title(\"Number of Divisions\")\n",
    "plt.xlabel(\"Time (hrs)\")\n",
    "plt.ylabel(\"Cell trace\")\n",
    "plt.savefig(mpath + \"/graphs/experiments/heatmaps/divs_hm.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap example for FOXO/p53 data -- edit as desired.\n",
    "This is an approach that works for combining cells across multiple positions from the same experiment, detailed in the *labels.csv* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrices = []\n",
    "lower = np.array(list(labels.values()))[:,0]\n",
    "upper = np.array(list(labels.values()))[:,9]\n",
    "nframes = 144\n",
    "for i in range(len(lower)):\n",
    "    r = range(lower[i], upper[i]+1)\n",
    "    if (upper[i] == 139):\n",
    "        r =  range(lower[i], upper[i])\n",
    "    foxo_heatmap_values = generate_heatmap_array(data, nframes, \"foxo_ratio\", positions = r)\n",
    "    p53_heatmap_values = generate_heatmap_array(data, nframes, \"p53_nuc\", positions = r)\n",
    "    all_matrices.append([foxo_heatmap_values,p53_heatmap_values])#, p53_heatmap_values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(labels.keys())\n",
    "#names = [\"E1\", \"E2\", \"E3\"]\n",
    "#names = [\"E1\"]\n",
    "os.makedirs(mpath + \"/graphs/experiments/heatmaps\", exist_ok=True)\n",
    "for i, data in enumerate(excluded):\n",
    "    colormap_input = generate_colormap_data(data[0])\n",
    "    colormap_input = np.array(colormap_input)\n",
    "    y = np.linspace(0,1,len(colormap_input))\n",
    "    print(np.sum(colormap_input)/len(colormap_input))\n",
    "    ext = [y[0]-(y[1]-y[0])/2., y[-1]+(y[1]-y[0])/2.,len(colormap_input),0]\n",
    "    plt.rcParams[\"figure.figsize\"] = 2,5\n",
    "    plt.imshow(colormap_input[:,np.newaxis], cmap = 'Greys', aspect = \"auto\", extent = ext)\n",
    "    plt.show()\n",
    "    g = sns.heatmap(data[1], cmap = \"viridis\", vmin = .03, vmax = 0.06)\n",
    "    g.set_facecolor('gray')\n",
    "    plt.title(\"p53 traces, \"+names[i])\n",
    "    plt.savefig(mpath + \"/graphs/experiments/heatmaps/p53_\"+names[i]+\".svg\")\n",
    "    plt.show()\n",
    "    #scale = np.nanpercentile(data[1], 99)\n",
    "    #print(scale)\n",
    "    #scale_l = np.nanpercentile(data[1], 10)\n",
    "    #g = sns.heatmap(data[1], cmap = \"viridis\", vmin = scale_l, vmax = scale)\n",
    "    #g.set_facecolor('gray')\n",
    "    #plt.title(\"p53 traces, \"+names[i])\n",
    "    #plt.savefig(path + \"/graphs/experiments/heatmaps/trial/p53_\"+names[i]+\".png\")\n",
    "    #plt.show()\n",
    "#plt.rcParams[\"figure.figsize\"] = 5,2\n",
    "\n",
    "#x = np.linspace(-3,3)\n",
    "#y = np.cumsum(np.random.randn(50))+6\n",
    "\n",
    "# fig, (ax,ax2) = plt.subplots(nrows=2, sharex=True)\n",
    "\n",
    "# extent = [x[0]-(x[1]-x[0])/2., x[-1]+(x[1]-x[0])/2.,0,1]\n",
    "# ax.imshow(y[np.newaxis,:], cmap=\"plasma\", aspect=\"auto\", extent=extent)\n",
    "# ax.set_yticks([])\n",
    "# ax.set_xlim(extent[0], extent[1])\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cd4b6a",
   "metadata": {},
   "source": [
    "## Load saved results object for further exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e82c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.read_pickle(fpath + \"/results.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization in napari.\n",
    "from oyLabImaging.Processing.imvisutils import get_or_create_viewer\n",
    "\n",
    "viewer = get_or_create_viewer()\n",
    "\n",
    "viewer.layers.clear()\n",
    "position_to_view = '0'\n",
    "R.show_images(pos=str(position_to_view), Channel=[nuc_mark],cmaps=['red'])\n",
    "R.show_images(pos = str(position_to_view), Channel = [cyto_mark], cmaps = ['green'])\n",
    "R.show_tracks(pos=str(position_to_view))\n",
    "R.track_explorer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f59a1a1",
   "metadata": {},
   "source": [
    "## Movie Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b59e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#requires a computer with functional napari viewer\n",
    "from oyLabImaging.Processing.imvisutils import get_or_create_viewer\n",
    "from oyLabImaging.Processing.imvisutils import export_napari_to_movie\n",
    "import oyLabImaging\n",
    "#might crash if you generate too many movies.\n",
    "#if you want to include other visual elements, you'll have to add new functionality to/consult the Results object in the oyLabImaging package\n",
    "positionlist = R.PosLbls.keys()\n",
    "viewer = get_or_create_viewer()\n",
    "for i in positionlist:\n",
    "    viewer.layers.clear()\n",
    "    position_to_view = i\n",
    "    g = R.PosLbls[i]\n",
    "    track_inds, track_labels = gen_full_tracks(g.trackinds)\n",
    "    R.show_images(pos=str(position_to_view), Channel=[nuc_mark],cmaps=['gray'])\n",
    "    R.show_tracks(pos=str(position_to_view), J = track_labels)\n",
    "    #take movie snapshot of current napari window.\n",
    "    os.makedirs(mpath + \"/processed_movie\",exist_ok=True)\n",
    "    movie_label = \"pos_\"+str(i)+\"_tracks\"\n",
    "    export_napari_to_movie(fname=mpath + '/processed_movie/Napari_movie_'+movie_name+'_'+movie_label+'.mov')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
